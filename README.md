# Framerate.cl - Arquitectura y Patrones de Dise√±o

![Bun](https://img.shields.io/badge/Bun-000000?style=flat-square&logo=bun&logoColor=white)
![Turborepo](https://img.shields.io/badge/Turborepo-EF2D5E?style=flat-square&logo=turborepo&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat-square&logo=typescript&logoColor=white)
![React](https://img.shields.io/badge/React-20232a?style=flat-square&logo=react&logoColor=61DAFB)
![Hono](https://img.shields.io/badge/Hono-E05D44?style=flat-square&logo=hono&logoColor=white)
![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=flat-square&logo=supabase&logoColor=white)
![Cloudflare](https://img.shields.io/badge/Cloudflare-F38020?style=flat-square&logo=cloudflare&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white)
![Biome](https://img.shields.io/badge/Biome-60A5FA?style=flat-square&logo=biome&logoColor=white)

**Sistema de Comparaci√≥n de Precios para Componentes PC**  
*Documento T√©cnico - Diciembre 2025*

## 1. Introducci√≥n

### 1.1 Visi√≥n General
Framerate.cl es una plataforma de comparaci√≥n de precios especializada en componentes de PC para el mercado chileno. El sistema est√° dise√±ado con una arquitectura modular que separa claramente las responsabilidades entre scraping, almacenamiento y presentaci√≥n de datos, garantizando escalabilidad, mantenibilidad y seguridad.

### 1.2 Principios Arquitect√≥nicos
*   **Separaci√≥n de Responsabilidades:** Cada componente tiene un prop√≥sito √∫nico y bien definido.
*   **Aislamiento del Scraping:** Los crawlers operan completamente aislados del usuario final.
*   **√önica Fuente de Verdad:** Supabase PostgreSQL como base de datos centralizada.
*   **Edge-First:** Distribuci√≥n global mediante Cloudflare para latencia m√≠nima.
*   **Monorepo Compartido:** C√≥digo, tipos y l√≥gica compartida en un √∫nico repositorio.

## 2. Arquitectura de Capas

### 2.1 Capa de Presentaci√≥n (apps/web)
El frontend es una aplicaci√≥n moderna construida con **React Router v7** (anteriormente Remix). Utiliza **Server-Side Rendering (SSR)** con **Tailwind CSS v4** y **Vite** como bundler. Aunque utiliza renderizado en el servidor, mantiene la separaci√≥n de responsabilidades consumiendo la API p√∫blica.

> **Estado Actual:** El frontend est√° en etapa inicial con la estructura base configurada (SSR habilitado, routing, estilos). Pendiente: implementar vistas de productos, consumo de API, y despliegue en Cloudflare Pages.

> **Patr√≥n:** El frontend (incluso en el lado del servidor) nunca accede directamente a la base de datos. Toda comunicaci√≥n pasa por la API Gateway implementada en Workers, garantizando seguridad y control de acceso centralizado.

### 2.2 Capa de API (apps/api)
Los Cloudflare Workers funcionan como API Gateway. Implementados con **Hono framework**, proporcionan endpoints RESTful con rate limiting y validaci√≥n de requests. Esta capa tiene acceso de solo lectura a Supabase utilizando la anon key con Row Level Security.

**Endpoints Implementados:**
- `GET /v1/products` - Listado con filtros (categor√≠a, marca, precio, specs)
- `GET /v1/products/:slug` - Detalle de producto con listings y variantes
- `GET /v1/products/search` - B√∫squeda por t√©rmino
- `GET /v1/categories` - Listado de categor√≠as
- `GET /v1/images/:path` - Proxy de im√°genes con cache

**Middleware Activo:**
- Rate limiting por IP (100 req/15min)
- Cache API para respuestas (listados: 5min, detalles: 1hr)
- CORS restringido a dominios permitidos
- Security headers

### 2.3 Capa de Datos (Supabase)
Supabase PostgreSQL funciona como √∫nica fuente de verdad. Almacena productos can√≥nicos, listings de tiendas, hist√≥rico de precios y metadatos. La seguridad se implementa mediante Row Level Security policies que permiten lectura p√∫blica pero escritura restringida √∫nicamente al scraper mediante service role key.

### 2.4 Capa de Scraping (apps/scraper)
El sistema de scraping opera completamente aislado y est√° dise√±ado para ser deployable utilizando Docker, a diferencia del resto de las aplicaciones. Esto permite ejecutar el scraper en entornos controlados y reproducibles, independientemente de la infraestructura subyacente. 

No expone APIs p√∫blicas ni acepta conexiones entrantes. Su √∫nica funci√≥n es extraer datos de tiendas, procesarlos y escribirlos a Supabase. Esta separaci√≥n garantiza que problemas en los crawlers nunca afecten la experiencia del usuario final. Adem√°s, el uso de Docker facilita la escalabilidad horizontal y el despliegue en servidores dedicados o entornos locales.

## 3. Patrones de Dise√±o para Scraping

### 3.1 Patr√≥n: Base Crawler Abstracto
Todos los crawlers heredan de una clase base abstracta (`BaseCrawler`) que define el contrato y comportamiento com√∫n. Esto garantiza consistencia y facilita la adici√≥n de nuevas tiendas sin duplicar l√≥gica.

**Responsabilidades del BaseCrawler (Implementado ‚úÖ):**
*   Rate limiting configurable por tienda (`requestDelay`)
*   Pool de p√°ginas Puppeteer para concurrencia controlada
*   Logging estructurado de operaciones
*   Fetch con headers realistas (User-Agent, Sec-Ch-Ua, etc.)
*   Bloqueo de recursos innecesarios (im√°genes, fonts, CSS) para velocidad
*   Procesamiento por lotes (`fetchHtmlBatch`)

**Pendiente de implementar:**
*   Respeto por robots.txt
*   Backoff exponencial en errores HTTP
*   User-Agent rotation (actualmente 1 UA fijo)
*   Proxy management

### 3.2 Patr√≥n: Strategy para Selectores
Cada tienda tiene su propia estrategia de extracci√≥n implementada como un conjunto de selectores y transformadores. Cuando una tienda cambia su HTML, solo se actualiza su estrategia espec√≠fica sin afectar otros crawlers.

**Crawlers Implementados:**
- `PcExpressCrawler`: Usa HTMLRewriter de Bun para parsing r√°pido sin JS
- `SpDigitalCrawler`: Usa Puppeteer (headless) + meta tags estructurados

**Categor√≠as Soportadas (10):** GPU, CPU, PSU, Motherboard, Case, RAM, HDD, SSD, Case Fan, CPU Cooler

**Pendiente:** Versionado de selectores y fallback autom√°tico

### 3.3 Procesamiento Concurrente
El scraping utiliza **Bun Workers** para procesamiento en paralelo y **Kuron** para scheduling de tareas programadas (cron cada 4 horas).

**Arquitectura Actual:**
- Workers procesan productos en lotes de 4 (`BATCH_SIZE`)
- Pool de p√°ginas Puppeteer con concurrencia configurable (3-4 p√°ginas)
- Procesamiento s√≠ncrono por categor√≠a con paralelizaci√≥n interna

> **Nota:** El sistema actual no usa colas distribuidas (BullMQ). Los jobs se procesan directamente en el worker que los inicia. Para escalar horizontalmente, se planea migrar a un sistema de colas real.

### 3.4 Matching de Productos
El matching de productos entre tiendas utiliza actualmente el **MPN (Manufacturer Part Number)** como identificador √∫nico.

**Algoritmo de Matching (Implementado):**
1.  Extraer MPN del t√≠tulo, metadatos o meta tags del producto
2.  Buscar en base de datos por MPN exacto (`findExistingProduct`)
3.  Si existe, actualizar specs y crear/actualizar listing
4.  Si no existe, crear nuevo producto can√≥nico

**Pendiente de implementar:**
- Fingerprinting de especificaciones normalizadas
- Score de confianza por m√©todo de match
- Cola de revisi√≥n manual para matches dudosos
- Agrupaci√≥n autom√°tica de variantes (`product_groups`)

> **Nota:** El campo EAN fue removido del schema. El matching se basa exclusivamente en MPN.

### 3.5 Patr√≥n: Normalizaci√≥n de Datos
Los datos scrapeados pasan por un pipeline de normalizaci√≥n extensivo antes de almacenarse.

**Pipeline Implementado:**
1. **Normalizaci√≥n de t√≠tulos** (`normalizers/`): Limpieza y estandarizaci√≥n por categor√≠a
2. **Extracci√≥n de specs** (`processors/`): Regex + mapeo de claves a formato can√≥nico
3. **Extracci√≥n IA** (`processors/ai/`): LLM (Groq/DeepSeek) para specs complejas con cache en BD
4. **Validaci√≥n de productos**: Filtros por t√©rminos excluidos ("caja abierta", "usado", etc.)
5. **Procesamiento de im√°genes**: Compresi√≥n con Sharp, upload a Supabase Storage

**Normalizadores por Categor√≠a:** GPU, CPU, PSU, Motherboard, Case, RAM, HDD, SSD, Case Fan, CPU Cooler

> **Cache de IA:** Las extracciones de specs por IA se cachean en `cached_specs_extractions` usando MPN como clave.

### 3.6 Patr√≥n: Incremental Updates
El scraper no reescribe toda la base de datos en cada ejecuci√≥n.

**Implementado:**
- Upsert de listings por `(store_id, external_id)` - solo actualiza si cambi√≥
- `last_scraped_at` se actualiza en cada scrape
- Hist√≥rico de precios en tabla `price_history` (registro por cada scrape)
- Cache de marcas en memoria para evitar race conditions

**Pendiente:**
- Comparaci√≥n de hashes para detectar cambios reales (evitar writes innecesarios)
- Detecci√≥n de productos descontinuados

## 4. Estrategias de Modularidad

### 4.1 Shared Types Package
Todos los tipos TypeScript se definen en `packages/db` y se importan en todas las apps. Esto garantiza que frontend, API y scraper hablen el mismo lenguaje.

**Estructura de packages/db:**
- `types.ts`: Tipos autogenerados de Supabase (`Database`, `Tables`, `TablesInsert`)
- `specs.ts`: Interfaces de especificaciones por categor√≠a (`GpuSpecs`, `CpuSpecs`, etc.)
- `storage.ts`: Utilidades para Supabase Storage (buckets, URLs, validaci√≥n)

### 4.2 Crawlers como M√≥dulos
Cada tienda es una clase independiente que extiende `BaseCrawler`. Agregar una nueva tienda consiste en:
1. Crear archivo en `crawlers/` implementando `parseProduct` y `getProductUrls`
2. Definir mapeo de categor√≠as a URLs
3. Registrar en el worker (`scraper.worker.ts`)

**Tiendas Implementadas:** PC Express, SP Digital

### 4.3 Configuration as Code
Toda configuraci√≥n vive en c√≥digo TypeScript con tipos estrictos. No hay archivos JSON o YAML que puedan corromperse. Las configuraciones de tiendas incluyen URLs base, selectores, rate limits, y headers HTTP. Los cambios se versionan en Git y se despliegan at√≥micamente.

### 4.4 Domain-Driven Design
El c√≥digo est√° organizado por dominios de negocio, no por capas t√©cnicas. Existe un dominio Product, uno Listing, uno Store, etc. Cada dominio tiene sus entidades, repositorios, servicios y validadores. Esto facilita el razonamiento sobre el c√≥digo y previene acoplamiento excesivo.

## 5. Resiliencia y Manejo de Errores

### 5.1 Graceful Degradation (‚úÖ Implementado)
Si algunos campos no se pueden extraer (por ejemplo, el MPN no est√° presente), el scraper contin√∫a con los datos disponibles. Los productos sin MPN se crean igualmente. La extracci√≥n IA tiene fallback a procesadores regex si falla.

### 5.2 Manejo de Race Conditions (‚úÖ Implementado)
- Cache en memoria de marcas (`brandCache`) con deduplicaci√≥n de promesas
- Manejo de errores de clave duplicada (c√≥digo 23505) con retry
- Upsert at√≥mico de listings por constraint √∫nico

### 5.3 Rate Limiting de IA (‚úÖ Implementado)
- `RateLimiter` class para Groq API (10 RPM)
- Retry autom√°tico en errores 429 con delay de 5s

### 5.4 Pendiente de Implementar
- **Circuit Breaker:** Marcar tiendas como unavailable temporalmente despu√©s de N fallos
- **Dead Letter Queue:** Cola de jobs fallidos para an√°lisis
- **M√©tricas estructuradas:** Dashboards de salud por tienda
- **Alertas autom√°ticas:** Notificaciones cuando selectores dejan de funcionar

## 6. Optimizaci√≥n de Performance

### 6.1 Caching en API (‚úÖ Implementado)
Los Workers cachean respuestas usando la **Cache API** de Cloudflare (no KV):
- Listados de productos: 5 minutos (`max-age=300`)
- Detalles de producto: 1 hora (`max-age=3600`)
- Im√°genes proxy: 1 a√±o (`max-age=31536000, immutable`)

> **Nota:** En desarrollo local (Bun), el cache se desactiva autom√°ticamente ya que la Cache API no est√° disponible.

### 6.2 Batch Processing (‚úÖ Implementado)
El scraper procesa en lotes de 4 productos simult√°neos (`BATCH_SIZE = 4`). Cada lote:
- Obtiene HTML en paralelo
- Parsea productos concurrentemente
- Escribe a BD (no en batch SQL, pero reduce round-trips de fetch)

### 6.3 Indexaci√≥n en Base de Datos (‚úÖ Implementado)
Migraciones de √≠ndices optimizados:
- `20251125064000_add_indexes_for_foreign_keys.sql`
- `20251125063000_fix_rls_performance.sql`
- Funci√≥n `filter_products` con filtros eficientes

### 6.4 Procesamiento de Im√°genes (‚úÖ Implementado)
- Im√°genes descargadas y comprimidas con **Sharp**
- Conversi√≥n autom√°tica a WebP
- Resize progresivo si excede l√≠mite de tama√±o
- Upload a Supabase Storage con deduplicaci√≥n por MPN

## 7. Consideraciones de Seguridad

### 7.1 Separaci√≥n de Credenciales (‚úÖ Implementado)
| Capa | Key | Permisos |
|------|-----|----------|
| Scraper | `SUPABASE_SERVICE_ROLE_KEY` | Lectura/Escritura completa |
| API | `SUPABASE_PUBLISHABLE_KEY` | Solo lectura (RLS) |
| Frontend | Ninguna | Sin acceso directo a BD |

### 7.2 Rate Limiting en API (‚úÖ Implementado)
- 100 requests por IP cada 15 minutos
- Usa header `CF-Connecting-IP` para identificar clientes
- Respuesta 429 con mensaje descriptivo

### 7.3 Row Level Security (‚úÖ Implementado)
Todas las tablas tienen RLS habilitado:
- Lectura p√∫blica para productos, listings, categor√≠as, tiendas
- Escritura restringida a service role
- Usuarios autenticados pueden gestionar sus quotes y alertas

### 7.4 Headers de Seguridad (‚úÖ Implementado)
- `secureHeaders()` middleware de Hono
- CORS restringido a `framerate.cl` y `localhost:3000`

### 7.5 Pendiente
- Sanitizaci√≥n expl√≠cita de HTML scrapeado (actualmente impl√≠cita en el parsing)

## 8. Plan de Escalabilidad

### 8.1 Arquitectura Actual
- **Scraper:** Bun Workers con procesamiento s√≠ncrono por categor√≠a
- **API:** Cloudflare Workers (serverless, escala autom√°ticamente)
- **BD:** Supabase PostgreSQL (plan gratuito actualmente)

### 8.2 Opciones de Escalado Horizontal
1. **M√∫ltiples instancias de scraper** con particionamiento por tienda
2. **Migraci√≥n a colas reales** (BullMQ + Redis) para distribuci√≥n de jobs
3. **Read replicas** de Supabase para separar tr√°fico de lectura

### 8.3 Optimizaciones Futuras
- Cloudflare R2 para im√°genes (en lugar de Supabase Storage)
- Cloudflare KV para cache distribuido
- Workers KV para rate limiting distribuido

## 9. Mantenibilidad a Largo Plazo

### 9.1 Testing (‚úÖ Parcialmente Implementado)
**Tests existentes en `apps/scraper/tests/`:**
- `gpu-normalization.test.ts` - Normalizaci√≥n de t√≠tulos de GPUs
- `psu-normalization.test.ts` - Normalizaci√≥n de PSUs
- `motherboard-normalization.test.ts` - Normalizaci√≥n de motherboards
- `cpu-cooler-normalization.test.ts` - Normalizaci√≥n de coolers
- `case-normalization.test.ts` - Normalizaci√≥n de gabinetes
- `ia-extraction.test.ts` - Extracci√≥n con IA
- `psu-ia-extraction.test.ts` - Extracci√≥n IA de PSUs

**Pendiente:**
- Fixtures de HTML para tests de crawlers
- Integration tests end-to-end
- Tests de API endpoints

### 9.2 Migraciones Versionadas (‚úÖ Implementado)
M√°s de 30 migraciones SQL en `packages/db/supabase/migrations/`. Cada cambio al schema es versionado y reproducible.

### 9.3 Documentaci√≥n
- README en cada package/app
- Tipos TypeScript como documentaci√≥n
- Comentarios en normalizadores explicando l√≥gica

## 10. Estado Actual y Roadmap

### 10.1 Completado ‚úÖ
- [x] Setup monorepo con Turborepo + Bun
- [x] Schema de Supabase con 2 tiendas (PC Express, SP Digital)
- [x] Crawlers funcionales para 10 categor√≠as
- [x] Pipeline de normalizaci√≥n completo
- [x] Extracci√≥n de specs con IA (Groq/DeepSeek)
- [x] API REST con endpoints de productos y categor√≠as
- [x] Rate limiting y cache en API
- [x] Storage de im√°genes con compresi√≥n
- [x] Hist√≥rico de precios
- [x] Tests de normalizaci√≥n

### 10.2 En Progreso üöß
- [ ] Frontend funcional con listado y comparaci√≥n
- [ ] B√∫squeda avanzada con filtros de specs
- [ ] Agrupaci√≥n autom√°tica de variantes

### 10.3 Pendiente üìã
- [ ] Sistema de colas distribuidas (BullMQ/Redis)
- [ ] Circuit breaker y dead letter queue
- [ ] Fingerprinting para matching avanzado
- [ ] Alertas de precio para usuarios
- [ ] Comparador de builds
- [ ] Despliegue en Cloudflare Pages (web)
- [ ] M√©tricas y dashboards
- [ ] M√°s tiendas (EyL Store, AllTec, etc.)

---

> **Nota:** Este documento refleja el estado real de implementaci√≥n a Diciembre 2025. La arquitectura est√° dise√±ada para ser implementada incrementalmente.